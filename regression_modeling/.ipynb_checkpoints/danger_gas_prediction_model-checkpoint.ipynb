{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS86x93wYY0A"
   },
   "source": [
    "#Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5l0OGtrjUc8O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5W6bhSXZ0Pj"
   },
   "source": [
    "#Функции/Классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vRyT_PqJfd8O"
   },
   "outputs": [],
   "source": [
    "def normalize_to_0_10(feature):\n",
    "    \"\"\"Нормализует данные в диапазон от 0 до 10.\"\"\"\n",
    "    min_val = np.min(feature)\n",
    "    max_val = np.max(feature)\n",
    "    normalized_feature = 10 * (feature - min_val) / (max_val - min_val)\n",
    "    return normalized_feature\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "def super_train_test_split(df: pd.DataFrame, y: pd.Series):\n",
    "    '''\n",
    "    Делит данные на две выборки: 1. строки, значения необходимого нам столбца не имеют пропусков.\n",
    "                                2. строки, значения необходимого нам столбца имеют пропуски.\n",
    "    Каждый из этих пунктов так же делиться на две выборки: а) необходимый столбец.\n",
    "                                                            б) остальные факторы.\n",
    "\n",
    "    Аргументы:\n",
    "        df: Pandas DataFrame, состоящий из факторов, инмеющих зависимость с признаком,\n",
    "            в котором необходимо заполнить пропуски.\n",
    "\n",
    "        y: Pandas Series, признак, пропуски которого необходимо заполнить.\n",
    "\n",
    "    небольшой комментарий:\n",
    "    У нас есть проблема - для заполенния пропусков с помощью какой-либо модели, необходимо,\n",
    "    чтобы ВСЕ значения в других признаках были заполнены(не было пропусков).\n",
    "    В противном случае модель ругается, что есть NaNы. Данный цикл устраняет данную проблему,\n",
    "    временно заполняя пропуски в столбцах на медиану всех значений признака\n",
    "    (кроме столбца, задача для которого изначально была заполнить пропуски с помощью модели).\n",
    "    Дальше смотрите по комментариям\n",
    "    '''\n",
    "    X = df.copy()\n",
    "\n",
    "    y_train = y[y.isnull() == False] # отбираем для тренировки те строки, в которых присутсвуют данные\n",
    "    y_temp = y[y.isnull()] # просто мусор. Полезный\n",
    "\n",
    "    idxs = y_temp.index # берём иднексы мусора(индексы,\n",
    "                      # в строках которых есть пропуски, которые необходимо заполнить)\n",
    "    X_train = X.drop(idxs) # делаем обучающую выборку из строк, в которых нет пропусков\n",
    "\n",
    "    idxs = y_train.index # берём иднексы c изначально заполенными значениями\n",
    "    X_test = X.drop(idxs) # отбрасываем строки с заполненными значениями в нужном нам столбце.\n",
    "                        # Получается выборка с данными, на основе которых будут\n",
    "                        # предсказываться пропущенные значения\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_temp\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "def split_for_grade(df: pd.DataFrame, target_column: pd.Series): # просто раздел данных на\n",
    "                                                                 # выборки для обучения и тестирования\n",
    "    X = df.copy()\n",
    "\n",
    "    if target_column.name in X.columns:\n",
    "        X.pop(target_column.name)\n",
    "    y = target_column\n",
    "    y1 = y[y.isnull() == False] # отбираем для тренировки те строки, в которых присутсвуют данные\n",
    "    y_temp = y[y.isnull()] # просто мусор. Полезный\n",
    "\n",
    "    idxs = y_temp.index # берём иднексы мусора(индексы,\n",
    "                      # в строках которых есть пропуски, которые необходимо заполнить)\n",
    "    X = X.drop(idxs) # делаем обучающую выборку из строк, в которых нет пропусков\n",
    "\n",
    "    y1 = y1.reset_index(drop=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y1, test_size=0.2, random_state=42)\n",
    "    return X_train.values, X_test.values, y_train.values, y_test.values\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "def best_factors_by_sbs(model, df: pd.DataFrame, list_of_factors: list):\n",
    "    \"\"\"\n",
    "    Вычисляет лучшую комбинацию факторов для обучения модели.\n",
    "\n",
    "    Аргументы:\n",
    "        model: регрессионная модель.\n",
    "        df: Pandas DataFrame со столбцом 'stage_4_output_danger_gas'.\n",
    "        list_of_factors: пустой список для лучшей комбинации факторов.\n",
    "    \"\"\"\n",
    "    # Инициализируем алгоритм sbs.\n",
    "    sbs = SBS(model, k_features=1)\n",
    "\n",
    "    y = df['stage_4_output_danger_gas']\n",
    "    X = df.copy()\n",
    "    X.pop('stage_4_output_danger_gas')\n",
    "\n",
    "    # Создаём временные названия для факторов в формате чисел.\n",
    "    new_names = [i for i in range(len(df.columns))]\n",
    "\n",
    "    # Обучение модели и перебор всех факторов для нахождения лучшей комбинации.\n",
    "    sbs.fit(X, y)\n",
    "\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    # Переименовываем столбцы в числовой вид.\n",
    "    X = X.rename(columns=dict(zip(X, new_names)))\n",
    "\n",
    "    # Инициализируем переменные для отбора лучшей комбинации признаков.\n",
    "    best_r2 = -1\n",
    "    best_mape = float('inf')\n",
    "    best_pair = None\n",
    "    lk = -1\n",
    "\n",
    "    # Перебираем полученные пары метрик для нахождения лучшей.\n",
    "    for i, (r2_sc, mape_sc) in enumerate(sbs.scores_):\n",
    "        if r2_sc > best_r2:\n",
    "            best_r2 = r2_sc\n",
    "            best_mape = mape_sc\n",
    "            best_pair = [r2_sc, mape_sc]\n",
    "            lk = list(sbs.subsets_[sbs.scores_.index([r2_sc, mape_sc])])\n",
    "\n",
    "            # Так как при создании списка индексов признаков не учитывается, что был удалён\n",
    "            # столбец, относительно которого ведутся вычесления, необходимо отредактировать\n",
    "            # созданный массив.\n",
    "            if df.columns.get_loc(y.name) in lk:\n",
    "                index = lk.index(df.columns.get_loc(y.name))\n",
    "                lk = np.array(lk)\n",
    "                if index < len(lk) - 1:\n",
    "                    lk = np.concatenate((lk[:index], lk[index:] + 1))\n",
    "                else:\n",
    "                    lk = lk[:index]\n",
    "            else:\n",
    "                for i in range(len(lk)):\n",
    "                    if lk[i] > df.columns.get_loc(y.name):\n",
    "                        lk[i] += 1\n",
    "\n",
    "            # Заполнения списка факторов.\n",
    "            list_of_factors = [col for col in list(df.columns[0:][lk]) if col != 'stage_4_output_danger_gas']\n",
    "\n",
    "    # Вывод всех результатов.\n",
    "    print(f\"Лучшая пара метрик: R2 = {best_pair[0]:.4f}, MAPE = {best_pair[1]:.4f}\")\n",
    "    print(f\"Метрики оценены на основе следующих факторов: {list_of_factors}\")\n",
    "    print('=-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-mbEElayfA9t"
   },
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    \"\"\"\n",
    "    Класс для последовательного обратного отбора признаков (Sequential Backward Selection).\n",
    "\n",
    "    Алгоритм отбирает подмножество наиболее важных признаков,\n",
    "    оптимизируя модель по метрикам качества (R-квадрат и MSE).\n",
    "\n",
    "    Аргументы:\n",
    "        estimator: Модель машинного обучения, которую нужно оптимизировать.\n",
    "                   Должна поддерживать методы fit и predict.\n",
    "        k_features: Целевое количество признаков для отбора.\n",
    "        test_size: Доля данных для тестирования (кросс-валидация).\n",
    "        random_state: Случайное зерно для воспроизводимости результатов.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, k_features, random_state=42):\n",
    "        self.estimator = clone(estimator) # Создаём копию модели, чтобы не менять исходную\n",
    "        self.k_features = k_features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает модель SBS и отбирает лучшие признаки.\n",
    "\n",
    "        Аргументы:\n",
    "            X: Матрица признаков.\n",
    "            y: Вектор целевой переменной.\n",
    "            own_split: Если True, использует пользовательскую функцию split_for_grade для разделения данных.\n",
    "        \"\"\"\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_for_grade(X, y)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = list(range(dim))  # Индексы всех признаков\n",
    "        self.subsets_ = [self.indices_] # Список всех подмножеств признаков\n",
    "        # Вычисляем R-SQUARED и MSE\n",
    "        score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            # Перебор всех возможных подмножеств с одним удаленным признаком\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            # находим подмножества с лучшими значениями метрик\n",
    "            best = np.argmax([i[0] for i in scores]) #  Выбираем подмножество с наибольшим r2_score,\n",
    "                                                     # т.к. данная метрика в приоритете. Так же отбор\n",
    "                                                     # лучшей комбинации будет происходит вне класса\n",
    "            self.indices_ = subsets[best]\n",
    "            #print(self.indices_)\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        \"\"\"\n",
    "        Вычисляет метрики R-SQUARED и MSE для заданного подмножества признаков.\n",
    "\n",
    "        Аргументы:\n",
    "            X_train, y_train, X_test, y_test, indices: Данные для обучения и оценки модели.\n",
    "        \"\"\"\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "\n",
    "        score = [r2_score(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred)]\n",
    "\n",
    "        return score  #scoring='neg_mean_squared_error' returns negative values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9TwRQniYgvP"
   },
   "source": [
    "#Инициализация датафрейма/регрессионных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDBHyhFtr2U1"
   },
   "source": [
    "Проверка на нескольких моделях необходима для более объективного, надежного и эффективного решения задачи, а также для понимания ограничений текущего подхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1SJ-yjLxZKYu"
   },
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    \"SVR\": SVR(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "    \"K-Nearest Neighbors Regressor (n_neighbors = 5)\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"K-Nearest Neighbors Regressor (n_neighbors = 3)\": KNeighborsRegressor(n_neighbors=3),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "F7b0XeNedSTc",
    "outputId": "a242b386-70c7-45c7-a184-2d1cbfc86e42"
   },
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "time_diffs = df['DateTime'].diff().dt.total_seconds()\n",
    "time_diffs = time_diffs.fillna(0)\n",
    "\n",
    "# нормализуем даты из столбца DateTime\n",
    "scaler = MinMaxScaler()\n",
    "normalized_diffs = scaler.fit_transform(time_diffs.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# вычисляет кумулятивную сумму элементов\n",
    "normalized_times = np.cumsum(normalized_diffs)\n",
    "\n",
    "# подставляем нормализованные значение\n",
    "df['DateTime'] = normalized_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfPn41mLWM2G"
   },
   "source": [
    "#Нормализация значений/иная предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjKyPs0aWGHl"
   },
   "source": [
    "Нормализация после обработки данных улучшила метрики предсказания главного столбца, так как масштабирование признаков предотвратило доминирование, обеспечило эффективное обучение и повысило точность прогнозов.\n",
    "\n",
    "нормализация значений совершается только для признаков с большим диапазоном значений. В данном случае было принято считать большой диапазон, если он больше 50.\n",
    "\n",
    "Значения нормализуются в диапазон от 0 до 10. Это действие поможет сохранить значимость факторов и при этом не делать эту значимость гигантской.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "wdPoHjelVn-4",
    "outputId": "e32c0521-17ee-4375-8c3d-05730f6cc251"
   },
   "outputs": [],
   "source": [
    "for col in df.columns[1:-2]:\n",
    "    if df[col].max() - df[col].min() > 50:\n",
    "        df[col] = normalize_to_0_10(df[col])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "zJM4pwi2gxqe",
    "outputId": "99441653-a2ea-48e4-8cf2-2e7cc4b06907"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xa08V0-nUsXR"
   },
   "outputs": [],
   "source": [
    "# Ограничение значений, которые больше 0.3 до 0.3 улучшило метрики при тестах, но более низкое значение ухудшило их,\n",
    "# вероятно, из-за искажения данных и потери информации.\n",
    "mask = (df['stage_4_output_danger_gas'] > 0.3)\n",
    "df.loc[mask, 'stage_4_output_danger_gas'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "Zpimqx6pXixw",
    "outputId": "8eab9b82-37d0-416d-b776-9af0dc3cf7a0"
   },
   "outputs": [],
   "source": [
    "sns.histplot(df['stage_4_output_danger_gas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём наборы данных исходя из лучшей комбинации факторов.\n",
    "X_train, X_test, y_train, y_true = split_for_grade(df.loc[:, ['DateTime', 'stage_2_output_bottom_pressure', 'stage_3_input_pressure', 'stage_4_input_steam', 'stage_4_output_dry_residue_avg']], df['stage_4_output_danger_gas'])\n",
    "# RFR модель показала себя лучше всех, поэтому используем её.\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Сохраняем предсказанные значения в pd.Series.\n",
    "predictions = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_predicted_gas_df = pd.DataFrame({'реальные_показатели': y_true, 'предсказанные_показатели': predictions})\n",
    "actual_predicted_gas_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_predicted_gas_df.to_csv(\"../danger_gas_values.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTnr0GMmWWVF"
   },
   "source": [
    "#Поиск лучшей модели, комбинации факторов и оценок метрик R2 и MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hyiF5zZ9dyw"
   },
   "source": [
    "Определяем лучшую модель из инициализированныз на основе метрики R2. Выводим метрики R2 и MAPE моделей с лучшей комбинацией факторов.\n",
    "\n",
    "Данный алгоритм занимает большое количество времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMsEadcug_vb",
    "outputId": "7b65a552-2d2c-4d0e-da5a-ddd1e387081a"
   },
   "outputs": [],
   "source": [
    "for model_name in regression_models:\n",
    "    list_of_factors = []\n",
    "    print(f\"Показатели модели {model_name}: \")\n",
    "    model = regression_models[model_name]\n",
    "    best_factors_by_sbs(model, df, list_of_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvgZ-cMxcgdc"
   },
   "source": [
    "#Выводы:\n",
    "\n",
    "##Оценка метрик: **R2 = 0.3932, MAPE = 0.1887**. Модель Random Forest Regressor.\n",
    "\n",
    "###**Неудовлетворительная прогностическая способность модели**: Проведенный анализ показал, что среди протестированных моделей наилучшие результаты достигнуты с помощью Random Forest Regressor (RFR), однако даже эта модель не продемонстрировала удовлетворительной прогностической способности в отношении доли опасного газа. Остальные модели, включая SVR, Decision Tree Regressor, Gradient Boosting Regressor, K-Nearest Neighbors Regressor (с n_neighbors = 5 и 3), показали худшие результаты. Несмотря на то, что RFR показал лучшие метрики (R2 = 0.3932 и MAPE = 0.1887), они по-прежнему свидетельствуют о том, что модель объясняет лишь небольшую долю дисперсии целевой переменной, а предсказания имеют значительные отклонения от фактических значений. Таким образом, RFR является лучшим выбором из рассмотренных моделей, но его прогностическая сила остается недостаточной.\n",
    "\n",
    "\n",
    "###**Недопустимость замены ручных замеров на основе текущей модели**: Принимая во внимание низкие показатели прогностической точности модели и существенную величину погрешности предсказаний, её использование в качестве замены ручных замеров доли опасного газа является недопустимым. Ошибки в предсказаниях, достигающие в среднем 19%, могут иметь критические последствия, особенно в контексте мониторинга потенциально опасных веществ. Таким образом, текущая модель не обеспечивает требуемой надежности и точности для принятия ответственных решений."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
